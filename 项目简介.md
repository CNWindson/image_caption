# 实战 看图说话机器人


## 简介
根据图片的内容自动的生成对图片的描述是计算机视觉和自然语言处理领域相结合的一个基础问题。

CNN模拟动物视觉神经网络的功能，善于处理图像类的视觉信息。

RNN因为其拥有记忆(state)所以可以记住输入序列的内容，并依据当前时刻向前或者向后的数据关系做出推断，善于处理序列数据，特别是自然语言处理类的问题。


前几周的作业，学员已经掌握了CNN的概念和用法，以及一些训练CNN的技巧。

第十周的作业中，学员们了解了RNN和word embeding(word2vector)的概念和原理。

本项目中，CNN和RNN会结合起来。由CNN提取图像中的信息，由RNN来生成对图像的描述。最终的结果如下图展示：
![result](https://raw.githubusercontent.com/tensorflow/models/master/research/im2txt/g3doc/example_captions.jpg)


## 作业内容
以tensorflow框架为基础，使用mscoco数据集的内容作为训练集，成功的搭建一个看图说话的系统出来。

作业中的论文内容参考这里：
https://arxiv.org/pdf/1411.4555.pdf

## 评价标准

### 成果1, 一整套可以运行的系统

包含代码和详细的文档。文档要求可操作。能够按照文档的描述搭建系统并运行。文档不全者不予及格。

- 要求文档能够详细解释系统中CNN，RNN，word embeading， beam searchim各个部分的构成及相互关系。
- beam search的算法原理的理解。
- 训练过程中踩到的一些坑和自己的心得。
- 对系统的输出结果的简单分析。


### 成果2, 提供系统演示的视频
视频内容：从任意图片网站上，随机下载一张图片送入系统，系统可以输出针对这张图片的场景生成的描述，描述尽量合理并与图片内容相关。


## 要点提示

- 系统的输入输出不做要求，能够正常演示即可。
    - 推荐的输入方式有：
        - 命令行直接指定待识别文件
        - 搭建一个web系统，使用表单方式上传文件
        - 搭建一个native程序，使用pyqt等GUI框架搭建GUI界面
    - 推荐的输出方式：
        - 将检测结果写入文件
        - 使用matplotlib显示检测结果
        - 搭建一个web系统，在web页上显示结果
        - 搭建一个native程序，使用pyqt等GUI框架搭建GUI界面

- 数据准备过程在linux系统上进行，尽量不要尝试在windows上进行数据的准备，会遇到各种奇怪的问题。
- 数据准备部分需要在本地完成，训练部分可以在tinymind上完成。
- 数据集选择，本作业可以使用的数据集有以下两个，建议使用flickr8k完成本作业，coco数据集太大，仅作为参考：
    - Flickr8K
        - 数据集的地址：http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/KCCA.html，coco的数据集比较大，也可以用这个数据集做。
    - mscoco
        - 数据集地址在这里。http://cocodataset.org/ 。数据集比较大，推荐用下载工具下载。这个作业只需要2014年的数据即可。2015年的数据可以不用下载。数据格式介绍请参考 http://cocodataset.org/#format 5. Caption generation的部分。
        - 数据有20个G左右，解压之后还要一部分空间，如果要做成tfrecord的话又要占用一部分空间。硬盘需要150G以上的空余空间。
        - 需要注意，学员的电脑可能会有硬盘出现坏道的情况，鉴于这里数据量比较大，请密切注意数据处理的过程，不要因为硬盘坏道之类的问题导致数据丢失，干扰项目的进行。
- CNN模型部分，可以使用Google提供的预训练模型来缩短训练的时间。
